{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline ID : dataclean\n",
    "\n",
    "### Input Description\n",
    "\n",
    "RAW OHLC data.\n",
    "\n",
    "### Output  \n",
    "\n",
    "Clean OHLC data in a hdf store\n",
    "\n",
    "### Operations\n",
    "\n",
    "This code takes a financial market data file and runs it through a processing pipeline. The following operations are carried out :\n",
    "\n",
    "- Localise the time data to market time\n",
    "- Merge with existing RAW data based on datetime\n",
    "- Save the resulting RAW data to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/repos/marketinsights-datasets/tradefair/tradefair.hdf\n",
      "Adding WallSt-hourly-120217.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-011116.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-210618.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-230718.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-050517.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-140518.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-040417.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-160517.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-091116.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-230617.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-200317.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-200318.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-061116.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-050617.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-180418.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-301016.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-021116.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-040618.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding WallSt-hourly-071116.txt to DOW table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Saved data to HDFStore: /WallSt-hourly\n",
      "Adding SP500-hourly-230617.txt to SPY table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/anaconda/envs/dev/lib/python3.6/site-packages/tables/path.py:112: NaturalNameWarning: object name is not a valid Python identifier: 'WallSt-hourly'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-040417.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-210618.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-200318.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-180418.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-140518.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-040618.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-230718.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-050517.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Adding SP500-hourly-050617.txt to SPY table\n",
      "Converting from Europe/London to US/Eastern\n",
      "Merging data...\n",
      "Saved data to HDFStore: /SP500-hourly\n",
      "/home/cwilkin/Development/repos/marketinsights-datasets/finam/finam.hdf\n",
      "Adding D&J-IND_150101_170519.csv to DOW table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/anaconda/envs/dev/lib/python3.6/site-packages/tables/path.py:112: NaturalNameWarning: object name is not a valid Python identifier: 'SP500-hourly'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting from US/Eastern to US/Eastern\n",
      "Merging data...\n",
      "Adding D&J-IND_161003_180319.csv to DOW table\n",
      "Converting from US/Eastern to US/Eastern\n",
      "Merging data...\n",
      "Adding D&J-IND_130101_141231.csv to DOW table\n",
      "Converting from US/Eastern to US/Eastern\n",
      "Merging data...\n",
      "Saved data to HDFStore: /D&J-IND\n",
      "Adding SANDP-500_161003_180319.csv to SPY table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/anaconda/envs/dev/lib/python3.6/site-packages/tables/path.py:112: NaturalNameWarning: object name is not a valid Python identifier: 'D&J-IND'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting from US/Eastern to US/Eastern\n",
      "Merging data...\n",
      "Adding SANDP-500_150101_170519.csv to SPY table\n",
      "Converting from US/Eastern to US/Eastern\n",
      "Merging data...\n",
      "Adding SANDP-500_130101_141231.csv to SPY table\n",
      "Converting from US/Eastern to US/Eastern\n",
      "Merging data...\n",
      "Saved data to HDFStore: /SANDP-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwilkin/Development/anaconda/envs/dev/lib/python3.6/site-packages/tables/path.py:112: NaturalNameWarning: object name is not a valid Python identifier: 'SANDP-500'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade ../../quantutils\n",
    "#git+https://github.com/cwilko/quantutils.git\n",
    "    \n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "    \n",
    "import quantutils.dataset.pipeline as ppl\n",
    "from quantutils.api.bluemix import ObjectStore\n",
    "from quantutils.api.marketinsights import MarketInsights\n",
    "\n",
    "PIPELINE_ID = \"marketdirection\"\n",
    "\n",
    "    \n",
    "##############\n",
    "## Pipeline ##\n",
    "##############\n",
    "\n",
    "CONFIG_FILE = \"../../marketinsights-datasets/rawConvert.json\"\n",
    "\n",
    "with open(CONFIG_FILE) as data_file:    \n",
    "    config = json.load(data_file)\n",
    "\n",
    "DS = config[\"datasources\"]\n",
    "\n",
    "objStore = ObjectStore('../cred/object_storage_cred.json')\n",
    "mi = MarketInsights('../cred/MIOapi_cred.json')\n",
    "\n",
    "markets = dict()\n",
    "## Loop over datasources...\n",
    "\n",
    "for datasource in DS:\n",
    "    \n",
    "    DS_path = config[\"dataPath\"] + datasource[\"name\"] + \"/\"\n",
    "    SRC_path = DS_path + \"raw/\"\n",
    "        \n",
    "    # Get HDFStore\n",
    "    hdfFile = DS_path + datasource[\"name\"] + \".hdf\"\n",
    "    print(hdfFile)\n",
    "    hdfStore = pandas.HDFStore(hdfFile)\n",
    "    \n",
    "    for timeseries in datasource[\"timeseries\"]:\n",
    "        \n",
    "        # Load Dataframe from store\n",
    "        if timeseries[\"name\"] in hdfStore:\n",
    "            tsData = hdfStore[timeseries[\"name\"]]\n",
    "        else:\n",
    "            tsData = pandas.DataFrame()\n",
    "                        \n",
    "        ## Loop over any source files...\n",
    "        for infile in os.listdir(SRC_path):          \n",
    "\n",
    "            newData = ppl.loadRawData(datasource, timeseries, SRC_path, infile)\n",
    "            if not newData is None:\n",
    "\n",
    "                ### RAW PIPELINE #############################################\n",
    "\n",
    "                newData = ppl.localize(newData, datasource[\"timezone\"], timeseries[\"timezone\"])\n",
    "                \n",
    "                tsData = ppl.merge(newData, tsData)                \n",
    "                \n",
    "                ##############################################################  \n",
    "        \n",
    "        ppl.save_hdf(tsData, timeseries[\"name\"], hdfStore)\n",
    "         \n",
    "\n",
    "hdfStore.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
