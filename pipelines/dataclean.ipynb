{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline ID : dataclean\n",
    "\n",
    "### Input Description\n",
    "\n",
    "RAW OHLC data.\n",
    "\n",
    "### Output  \n",
    "\n",
    "Clean OHLC data in a hdf store\n",
    "\n",
    "### Operations\n",
    "\n",
    "This code takes a financial market data file and runs it through a processing pipeline. The following operations are carried out :\n",
    "\n",
    "- Localise the time data to market time\n",
    "- Merge with existing RAW data based on datetime\n",
    "- Save the resulting RAW data to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade ../../quantutils\n",
    "#git+https://github.com/cwilko/quantutils.git\n",
    "    \n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "    \n",
    "import quantutils.dataset.pipeline as ppl\n",
    "from quantutils.api.auth import CredentialsFileStore\n",
    "from quantutils.api.bluemix import ObjectStore\n",
    "from quantutils.api.marketinsights import MarketInsights\n",
    "\n",
    "PIPELINE_ID = \"marketdirection\"\n",
    "\n",
    "    \n",
    "##############\n",
    "## Pipeline ##\n",
    "##############\n",
    "\n",
    "CONFIG_FILE = \"../../marketinsights-datasets/rawConvert.json\"\n",
    "\n",
    "with open(CONFIG_FILE) as data_file:    \n",
    "    config = json.load(data_file)\n",
    "\n",
    "DS = config[\"datasources\"]\n",
    "\n",
    "credStore = CredentialsFileStore('~/.marketinsights')\n",
    "objStore = ObjectStore(credStore)\n",
    "mi = MarketInsights(credStore)\n",
    "\n",
    "markets = dict()\n",
    "## Loop over datasources...\n",
    "\n",
    "for datasource in DS:\n",
    "    \n",
    "    DS_path = config[\"dataPath\"] + datasource[\"name\"] + \"/\"\n",
    "    SRC_path = DS_path + \"raw/\"\n",
    "        \n",
    "    # Get HDFStore\n",
    "    hdfFile = DS_path + datasource[\"name\"] + \".hdf\"\n",
    "    print(hdfFile)\n",
    "    hdfStore = pandas.HDFStore(hdfFile)\n",
    "    \n",
    "    for timeseries in datasource[\"timeseries\"]:\n",
    "        \n",
    "        # Load Dataframe from store\n",
    "        if timeseries[\"name\"] in hdfStore:\n",
    "            tsData = hdfStore[timeseries[\"name\"]]\n",
    "        else:\n",
    "            tsData = pandas.DataFrame()\n",
    "                        \n",
    "        ## Loop over any source files...\n",
    "        for infile in os.listdir(SRC_path):          \n",
    "\n",
    "            newData = ppl.loadRawData(datasource, timeseries, SRC_path, infile)\n",
    "            if not newData is None:\n",
    "\n",
    "                ### RAW PIPELINE #############################################\n",
    "\n",
    "                newData = ppl.localize(newData, datasource[\"timezone\"], timeseries[\"timezone\"])\n",
    "                \n",
    "                tsData = ppl.merge(newData, tsData)                \n",
    "                \n",
    "                ##############################################################  \n",
    "        \n",
    "        #ppl.save_hdf(tsData, timeseries[\"name\"], hdfStore)\n",
    "        # TODO : Back up to object storage\n",
    "         \n",
    "\n",
    "hdfStore.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
